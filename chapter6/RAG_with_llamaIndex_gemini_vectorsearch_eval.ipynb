{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Question Answering with Large Documents using LlamaIndex on Google cloud\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/use-cases/document-qa/question_answering_documents_langchain.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGidY33I0-J2"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Mona Mona](https://github.com/mona19) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn how to use llamaindex\n",
        "\n",
        "- Deploy Vertex AI vector search index\n",
        "- Load document for question answering\n",
        "- Chunk and embed documents using Vertex AI embeddings into Vector Search index.\n",
        "- Use Gemini model to ask questions to the index\n",
        "- Evalute faithfulness of the response\n",
        "- Cleanup- delete the Vertex AI Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uSGoyR6RrTQ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install Vertex AI SDK for LLamaIndex, other packages and their dependencies\n",
        "\n",
        "Install the following packages required to execute this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tvCecNMQpXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b505bb0-dabc-4353-d565-4053c464d3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.10.43)\n",
            "Collecting llama-index-vector-stores-vertexaivectorsearch\n",
            "  Downloading llama_index_vector_stores_vertexaivectorsearch-0.0.1-py3-none-any.whl (9.9 kB)\n",
            "Collecting llama-index-llms-vertex\n",
            "  Downloading llama_index_llms_vertex-0.1.8-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.7)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.12)\n",
            "Requirement already satisfied: llama-index-core==0.10.43 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.43)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.10)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.22)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.23)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.32.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (4.12.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.14.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.39.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-vertexaivectorsearch) (1.52.0)\n",
            "Collecting google-cloud-storage<3.0.0,>=2.16.0 (from llama-index-vector-stores-vertexaivectorsearch)\n",
            "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-vertex<0.2.0,>=0.1.0 (from llama-index-vector-stores-vertexaivectorsearch)\n",
            "  Downloading llama_index_embeddings_vertex-0.1.0-py3-none-any.whl (4.0 kB)\n",
            "Collecting pyarrow<16.0.0,>=15.0.2 (from llama-index-llms-vertex)\n",
            "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (24.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.7.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.16)\n",
            "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch)\n",
            "  Downloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (2.7.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (1.63.1)\n",
            "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.16.0->llama-index-vector-stores-vertexaivectorsearch) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.13.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.43->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.43->llama-index) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.43->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.43->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.43->llama-index) (3.21.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.43->llama-index) (1.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.39.0->llama-index-vector-stores-vertexaivectorsearch) (1.16.0)\n",
            "Installing collected packages: pyarrow, google-api-core, google-cloud-storage, llama-index-llms-vertex, llama-index-embeddings-vertex, llama-index-vector-stores-vertexaivectorsearch\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 15.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-api-core-2.19.0 google-cloud-storage-2.16.0 llama-index-embeddings-vertex-0.1.0 llama-index-llms-vertex-0.1.8 llama-index-vector-stores-vertexaivectorsearch-0.0.1 pyarrow-15.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pyarrow"
                ]
              },
              "id": "c315aecfb1644a5c9a3b2469172afaf2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install llama-index llama-index-vector-stores-vertexaivectorsearch llama-index-llms-vertex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only: Uncomment the following cell to restart the kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yStiAHorWE3Q"
      },
      "source": [
        "***Colab only***: Run the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUxT_k5TdgP"
      },
      "source": [
        "### Authenticating your notebook environment\n",
        "\n",
        "- If you are using **Colab** to run this notebook, run the cell below and continue.\n",
        "- If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbNgv4q1T2Mi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvb4hvFl0-J6"
      },
      "source": [
        "- If you are running this notebook in a local development environment:\n",
        "  - Install the [Google Cloud SDK](https://cloud.google.com/sdk).\n",
        "  - Obtain authentication credentials. Create local credentials by running the following command and following the oauth2 flow (read more about the command [here](https://cloud.google.com/sdk/gcloud/reference/beta/auth/application-default/login)):\n",
        "\n",
        "    ```bash\n",
        "    gcloud auth application-default login\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6aYWDwo0-J6"
      },
      "source": [
        "**Colab only:** Run the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjSsu6cmUdEx"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "# Project and Storage Constants\n",
        "PROJECT_ID = \"<>\"\n",
        "REGION = \"us-central1\"\n",
        "GCS_BUCKET_NAME = \"your bucket name\"\n",
        "GCS_BUCKET_URI = f\"gs://your bucket name\"\n",
        "\n",
        "# The number of dimensions for the textembedding-gecko@003 is 768\n",
        "# If other embedder is used, the dimensions would probably need to change.\n",
        "VS_DIMENSIONS = 768\n",
        "\n",
        "# Vertex AI Vector Search Index configuration\n",
        "# parameter description here\n",
        "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n",
        "VS_INDEX_NAME = \"llamaindex-doc-index\"  # @param {type:\"string\"}\n",
        "VS_INDEX_ENDPOINT_NAME = \"llamaindex-doc-endpoint\"\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)  # @param {type:\"string\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQmSRbKA8r-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511ae82b-1d74-41ec-e6d3-8f175f92724b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://faa_pdfs/...\n",
            "BadRequestException: 400 The specified location constraint is not valid.\n"
          ]
        }
      ],
      "source": [
        "# Create a bucket.\n",
        "! gsutil mb -l REGION−pREGION−pREGION -p PROJECT_ID $GCS_BUCKET_URI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE : This operation can take upto 30 seconds\n",
        "\n",
        "# check if index exists\n",
        "index_names = [\n",
        "    index.resource_name\n",
        "    for index in aiplatform.MatchingEngineIndex.list(\n",
        "        filter=f\"display_name={VS_INDEX_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(index_names) == 0:\n",
        "    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
        "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "        display_name=VS_INDEX_NAME,\n",
        "        dimensions=VS_DIMENSIONS,\n",
        "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "        shard_size=\"SHARD_SIZE_SMALL\",\n",
        "        index_update_method=\"STREAM_UPDATE\",\n",
        "        approximate_neighbors_count=100# allowed values BATCH_UPDATE , STREAM_UPDATE\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVPDVkHq5J95",
        "outputId": "b6ea3a71-c738-473e-9b02-7f82873e5808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index llamaindex-doc-index exists with resource name projects/474775107710/locations/us-central1/indexes/2289645003913297920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create an Endpoint **bold text**\n",
        "To use the index, you need to create an index endpoint. It works as a server instance accepting query requests for your index. An endpoint can be a public endpoint or a private endpoint.\n",
        "\n",
        "Let's create a public endpoint.bold text"
      ],
      "metadata": {
        "id": "TOLQBOT26Ow-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_names = [\n",
        "    endpoint.resource_name\n",
        "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
        "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n",
        "    )\n",
        "]\n",
        "\n",
        "if len(endpoint_names) == 0:\n",
        "    print(\n",
        "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
        "    )\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=endpoint_names[0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS8s5lGH6SNE",
        "outputId": "dbf508b8-5224-432a-fc57-5ab7139a7bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index endpoint llamaindex-doc-endpoint exists with resource name projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy Index to the Endpoint¶**\n",
        "With the index endpoint, deploy the index by specifying a unique deployed index ID.\n",
        "\n",
        "NOTE : This operation can take upto 30 minutes."
      ],
      "metadata": {
        "id": "2JK7q2Cg9DwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if endpoint exists\n",
        "index_endpoints = [\n",
        "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
        "    for deployed_index in vs_index.deployed_indexes\n",
        "]\n",
        "\n",
        "if len(index_endpoints) == 0:\n",
        "    print(\n",
        "        f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
        "    )\n",
        "    vs_deployed_index = vs_endpoint.deploy_index(\n",
        "    index=vs_index,\n",
        "    deployed_index_id=\"new_deployed_index_id\",\n",
        "    display_name=VS_INDEX_NAME,\n",
        "    machine_type=\"e2-standard-16\",\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=1,\n",
        "    )\n",
        "    print( f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )\n",
        "else:\n",
        "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
        "        index_endpoint_name=index_endpoints[0][0]\n",
        "    )\n",
        "    print(\n",
        "        f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pNiYWCd68wP",
        "outputId": "2ed180b8-7091-4231-a8fc-d1a3116666c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Search index llamaindex-doc-index is already deployed at endpoint llamaindex-doc-endpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules needed\n",
        "from llama_index.core import (\n",
        "    StorageContext,\n",
        "    Settings,\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        ")\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    MetadataFilters,\n",
        "    MetadataFilter,\n",
        "    FilterOperator,\n",
        ")\n",
        "from llama_index.llms.vertex import Vertex\n",
        "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
        "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore"
      ],
      "metadata": {
        "id": "ZdsO2dZQLLuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse, Index and Query PDFs using Vertex AI Vector Search and Gemini Pro**"
      ],
      "metadata": {
        "id": "G8GO1JKtK347"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p ./data/arxiv/\n",
        "! wget 'https://arxiv.org/pdf/1706.03762.pdf' -O ./data/arxiv/test.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1CZIsNNKrB-",
        "outputId": "ed507fbc-7da3-4a80-9458-6e26f808ef6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-07 14:47:47--  https://arxiv.org/pdf/1706.03762.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.195.42, 151.101.67.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://arxiv.org/pdf/1706.03762 [following]\n",
            "--2024-06-07 14:47:47--  http://arxiv.org/pdf/1706.03762\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215244 (2.1M) [application/pdf]\n",
            "Saving to: ‘./data/arxiv/test.pdf’\n",
            "\n",
            "\r./data/arxiv/test.p   0%[                    ]       0  --.-KB/s               \r./data/arxiv/test.p 100%[===================>]   2.11M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-06-07 14:47:47 (26.1 MB/s) - ‘./data/arxiv/test.pdf’ saved [2215244/2215244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/arxiv/\").load_data()\n",
        "print(f\"# of documents = {len(documents)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdybUAVyK_Qm",
        "outputId": "e838b7c2-a5b1-4254-d73d-cab16c278693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "! mkdir -p ./data/arxiv/\n",
        "! wget 'https://arxiv.org/pdf/1706.03762.pdf' -O ./data/arxiv/test.pdf"
      ],
      "metadata": {
        "id": "sVsUeOLoK1RC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGaTjPVTmhP"
      },
      "source": [
        "### Import models and intiatilze Vector Store\n",
        "\n",
        "You load the pre-trained text and embeddings generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITUmZiNZcMUW"
      },
      "outputs": [],
      "source": [
        "# setup storage\n",
        "vector_store = VertexAIVectorStore(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    index_id=vs_index.resource_name,\n",
        "    endpoint_id=vs_endpoint.resource_name,\n",
        "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
        ")\n",
        "\n",
        "# set storage context\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# configure embedding model\n",
        "embed_model = VertexTextEmbedding(\n",
        "    model_name=\"textembedding-gecko@003\",\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "vertex_gemini = Vertex(model=\"gemini-pro\", temperature=0, additional_kwargs={})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define index from vector store\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context,embed_model=embed_model\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "268jlr_RPK8R",
        "outputId": "16cd6a81-aafc-4424-f88e-e4826c088d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:Upserting datapoints MatchingEngineIndex index: projects/474775107710/locations/us-central1/indexes/2289645003913297920\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index:MatchingEngineIndex index Upserted datapoints. Resource name: projects/474775107710/locations/us-central1/indexes/2289645003913297920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "qUzqXWwPPNLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up Query engine with Gemini **"
      ],
      "metadata": {
        "id": "pU03APMkfdPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = vertex_gemini\n",
        "query_engine = index.as_query_engine(\n",
        "    llm=llm,\n",
        "    similarity_top_k=3,\n",
        ")"
      ],
      "metadata": {
        "id": "-Zqk19GPSAHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"who are the authors of paper Attention is All you need?\"\n",
        ")\n",
        "\n",
        "print(f\"Response:\")\n",
        "print(\"-\" * 80)\n",
        "print(response.response)\n",
        "print(\"-\" * 80)\n",
        "print(f\"Source Documents:\")\n",
        "print(\"-\" * 80)\n",
        "for source in response.source_nodes:\n",
        "    print(f\"Sample Text: {source.text[:50]}\")\n",
        "    print(f\"Relevance score: {source.get_score():.3f}\")\n",
        "    print(f\"File Name: {source.metadata.get('file_name')}\")\n",
        "    print(f\"Page #: {source.metadata.get('page_label')}\")\n",
        "    print(f\"File Path: {source.metadata.get('file_path')}\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42c95EKkQOIa",
        "outputId": "2f191df6-cc16-4558-89aa-fdeb2b2a9679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "--------------------------------------------------------------------------------\n",
            "The authors of the paper \"Attention Is All You Need\" are:\n",
            "\n",
            "* Ashish Vaswani\n",
            "* Noam Shazeer\n",
            "* Niki Parmar\n",
            "* Jakob Uszkoreit\n",
            "* Llion Jones\n",
            "* Aidan N. Gomez\n",
            "* Łukasz Kaiser\n",
            "* Illia Polosukhin\n",
            "--------------------------------------------------------------------------------\n",
            "Source Documents:\n",
            "--------------------------------------------------------------------------------\n",
            "Sample Text: Provided proper attribution is provided, Google he\n",
            "Relevance score: 0.719\n",
            "File Name: test.pdf\n",
            "Page #: 1\n",
            "File Path: /content/data/arxiv/test.pdf\n",
            "--------------------------------------------------------------------------------\n",
            "Sample Text: length nis smaller than the representation dimensi\n",
            "Relevance score: 0.687\n",
            "File Name: test.pdf\n",
            "Page #: 7\n",
            "File Path: /content/data/arxiv/test.pdf\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response Evaluation**\n",
        "\n",
        "Does the response match the retrieved context? Does it also match the query? Does it match the reference answer or guidelines? Here's a simple example that evaluates a single response for Faithfulness, i.e. whether the response is aligned to the context, such as being free from hallucinations:"
      ],
      "metadata": {
        "id": "EHuerdrDVizO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import FaithfulnessEvaluator"
      ],
      "metadata": {
        "id": "6UAjC_IlQVI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define evaluator\n",
        "evaluator = FaithfulnessEvaluator(llm=llm)"
      ],
      "metadata": {
        "id": "JFg3jfLAUdB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query index\n",
        "!pip install nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwftSatTVXE1",
        "outputId": "ecf4cd3e-7612-44f7-9915-8496762488f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The response contains both the response and the source from which the response was generated; the evaluator compares them and determines if the response is faithful to the source."
      ],
      "metadata": {
        "id": "PfnbuqoDVv8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "response = query_engine.query(\n",
        "    \"who are the authors of paper Attention is All you need?\"\n",
        ")\n",
        "eval_result = evaluator.evaluate_response(response=response)\n",
        "print(str(eval_result.passing))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAHgR44dUqb0",
        "outputId": "07ba174d-5f18-4036-96ba-8d52696b1334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Clean Up**\n",
        "\n",
        "Please delete Vertex AI Vector Search Index and Index Endpoint after running your experiments to avoid incurring additional charges. Please note that you will be charged as long as the endpoint is running.\n",
        "\n",
        "⚠️ NOTE: Enabling `CLEANUP_RESOURCES` flag deletes Vector Search Index, Index Endpoint and Cloud Storage bucket. Please run it with caution."
      ],
      "metadata": {
        "id": "LFzWQKD3Vs3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLEANUP_RESOURCES = True"
      ],
      "metadata": {
        "id": "Aj0LWj8AcATe"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undeploy indexes and Delete index endpoint"
      ],
      "metadata": {
        "id": "bNlzx-Nlcf-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if CLEANUP_RESOURCES:\n",
        "    print(\n",
        "        f\"Undeploying all indexes and deleting the index endpoint {vs_endpoint.display_name}\"\n",
        "    )\n",
        "    vs_endpoint.undeploy_all()\n",
        "    vs_endpoint.delete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swr3kHGycc2S",
        "outputId": "af9bdbbc-2395-4b89-a672-30974b27c118"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undeploying all indexes and deleting the index endpoint llamaindex-doc-endpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Undeploying MatchingEngineIndexEndpoint index_endpoint: projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:Undeploy MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992/operations/7024100600912543744\n",
            "INFO:google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint:MatchingEngineIndexEndpoint index_endpoint undeployed. Resource name: projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992\n",
            "INFO:google.cloud.aiplatform.base:Deleting MatchingEngineIndexEndpoint : projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992\n",
            "INFO:google.cloud.aiplatform.base:Delete MatchingEngineIndexEndpoint  backing LRO: projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992/operations/5739941388414353408\n",
            "INFO:google.cloud.aiplatform.base:MatchingEngineIndexEndpoint deleted. . Resource name: projects/474775107710/locations/us-central1/indexEndpoints/2278948954798292992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if CLEANUP_RESOURCES:\n",
        "    print(f\"Deleting the index {vs_index.display_name}\")\n",
        "    vs_index.delete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaxY7_qxckTZ",
        "outputId": "1debf6bc-d879-400f-b13f-037ac6fc6e54"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.base:Deleting MatchingEngineIndex : projects/474775107710/locations/us-central1/indexes/2289645003913297920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting the index llamaindex-doc-index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.base:Delete MatchingEngineIndex  backing LRO: projects/474775107710/locations/us-central1/indexes/2289645003913297920/operations/2752928935560871936\n",
            "INFO:google.cloud.aiplatform.base:MatchingEngineIndex deleted. . Resource name: projects/474775107710/locations/us-central1/indexes/2289645003913297920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if CLEANUP_RESOURCES and \"GCS_BUCKET_NAME\" in globals():\n",
        "    print(f\"Deleting contents from the Cloud Storage bucket {GCS_BUCKET_NAME}\")\n",
        "\n",
        "    shell_output = ! gsutil du -ash gs://GCS_BUCKET_NAME    print(shell_output)    print(        f\"Size of the bucket {GCS_BUCKET_NAME} before deleting = {' '.join(shell_output[0].split()[:2])}\"    )    # uncomment below line to delete contents of the bucket    # ! gsutil -m rm -r gs://GCS_BUCKET_NAME    print(shell_output)    print(        f\"Size of the bucket {GCS_BUCKET_NAME} before deleting = {' '.join(shell_output[0].split()[:2])}\"    )    # uncomment below line to delete contents of the bucket    # ! gsutil -m rm -r gs://GCS_BUCKET_NAME\n",
        "    print(shell_output)\n",
        "    print(\n",
        "        f\"Size of the bucket {GCS_BUCKET_NAME} before deleting = {' '.join(shell_output[0].split()[:2])}\"\n",
        "    )\n",
        "\n",
        "    # uncomment below line to delete contents of the bucket\n",
        "    # ! gsutil -m rm -r gs://GCS_BUCKET_NAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv5ZZvUucpK6",
        "outputId": "829d863a-c977-420d-ca6e-bdbb20e96054"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting contents from the Cloud Storage bucket faa_pdfs\n",
            "[\"/bin/bash: -c: line 1: syntax error near unexpected token `('\", '/bin/bash: -c: line 1: ` gsutil du -ash gs://GCS_BUCKET_NAME\\xa0\\xa0\\xa0\\xa0print(shell_output)\\xa0\\xa0\\xa0\\xa0print(\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0f\"Size\\xa0of\\xa0the\\xa0bucket\\xa0{GCS_BUCKET_NAME}\\xa0before\\xa0deleting\\xa0=\\xa0{\\'\\xa0\\'.join(shell_output[0].split()[:2])}\"\\xa0\\xa0\\xa0\\xa0)\\xa0\\xa0\\xa0\\xa0#\\xa0uncomment\\xa0below\\xa0line\\xa0to\\xa0delete\\xa0contents\\xa0of\\xa0the\\xa0bucket\\xa0\\xa0\\xa0\\xa0#\\xa0!\\xa0gsutil\\xa0-m\\xa0rm\\xa0-r\\xa0gs://GCS_BUCKET_NAME\\xa0\\xa0\\xa0\\xa0print(shell_output)\\xa0\\xa0\\xa0\\xa0print(\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0f\"Size\\xa0of\\xa0the\\xa0bucket\\xa0{GCS_BUCKET_NAME}\\xa0before\\xa0deleting\\xa0=\\xa0{\\'\\xa0\\'.join(shell_output[0].split()[:2])}\"\\xa0\\xa0\\xa0\\xa0)\\xa0\\xa0\\xa0\\xa0#\\xa0uncomment\\xa0below\\xa0line\\xa0to\\xa0delete\\xa0contents\\xa0of\\xa0the\\xa0bucket\\xa0\\xa0\\xa0\\xa0#\\xa0!\\xa0gsutil\\xa0-m\\xa0rm\\xa0-r\\xa0gs://GCS_BUCKET_NAME\\'']\n",
            "Size of the bucket faa_pdfs before deleting = /bin/bash: -c:\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-11.m111",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}