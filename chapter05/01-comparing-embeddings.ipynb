{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f160ed6-74a4-467a-860b-fd243eeb9e42",
   "metadata": {},
   "source": [
    "# One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10aec886-1765-4287-8cbc-513f4d080c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                   One-Hot Encoding                                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━┳━━━━━┳━━━━┳━━━━━━━━┳━━━━━┳━━━━━━━┳━━━━━━┳━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Sentence                       </span>┃<span style=\"font-weight: bold\"> cat </span>┃<span style=\"font-weight: bold\"> dog </span>┃<span style=\"font-weight: bold\"> on </span>┃<span style=\"font-weight: bold\"> played </span>┃<span style=\"font-weight: bold\"> rug </span>┃<span style=\"font-weight: bold\"> slept </span>┃<span style=\"font-weight: bold\"> soft </span>┃<span style=\"font-weight: bold\"> the </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━╇━━━━━╇━━━━╇━━━━━━━━╇━━━━━╇━━━━━━━╇━━━━━━╇━━━━━┩\n",
       "│ The cat slept on the soft rug. │ 1   │ 0   │ 1  │ 0      │ 1   │ 1     │ 1    │ 1   │\n",
       "│ The dog played on the rug.     │ 0   │ 1   │ 1  │ 1      │ 1   │ 0     │ 0    │ 1   │\n",
       "└────────────────────────────────┴─────┴─────┴────┴────────┴─────┴───────┴──────┴─────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                   One-Hot Encoding                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━┳━━━━━┳━━━━┳━━━━━━━━┳━━━━━┳━━━━━━━┳━━━━━━┳━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSentence                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcat\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mdog\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mon\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mplayed\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrug\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mslept\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msoft\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mthe\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━╇━━━━━╇━━━━╇━━━━━━━━╇━━━━━╇━━━━━━━╇━━━━━━╇━━━━━┩\n",
       "│ The cat slept on the soft rug. │ 1   │ 0   │ 1  │ 0      │ 1   │ 1     │ 1    │ 1   │\n",
       "│ The dog played on the rug.     │ 0   │ 1   │ 1  │ 1      │ 1   │ 0     │ 0    │ 1   │\n",
       "└────────────────────────────────┴─────┴─────┴────┴────────┴─────┴───────┴──────┴─────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\"The cat slept on the soft rug.\",\n",
    "          \"The dog played on the rug.\"]\n",
    "\n",
    "# Fit the vectorizer to your corpus\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "vectorizer.fit(corpus) \n",
    "\n",
    "# Get the vocabulary \n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Now transform the corpus using the fitted vocabulary\n",
    "one_hot_encoded = vectorizer.transform(corpus)\n",
    "\n",
    "# visualize\n",
    "df = pd.DataFrame(one_hot_encoded.toarray(), columns=vocabulary)\n",
    "df.insert(0, \"Sentence\", corpus)\n",
    "\n",
    "# ensure dataframe contains only string values\n",
    "df = df.astype(str)\n",
    "\n",
    "table = Table(title=\"One-Hot Encoding\")\n",
    "for col in df.columns:\n",
    "    table.add_column(col)\n",
    "for row in df.values:\n",
    "    table.add_row(*row)\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a69e46-d1ff-4f4d-96de-ac07d0b4c8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                                                                                   \n",
       " <span style=\"font-weight: bold\">   </span> <span style=\"font-weight: bold\"> Sentence                 </span> <span style=\"font-weight: bold\"> cat </span> <span style=\"font-weight: bold\"> dog </span> <span style=\"font-weight: bold\"> napped </span> <span style=\"font-weight: bold\"> on </span> <span style=\"font-weight: bold\"> peacefully </span> <span style=\"font-weight: bold\"> rug </span> <span style=\"font-weight: bold\"> slept </span> <span style=\"font-weight: bold\"> soft </span> <span style=\"font-weight: bold\"> soundly </span> <span style=\"font-weight: bold\"> the </span> <span style=\"font-weight: bold\"> warm </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  0   The cat slept soundly on     1     0        0    1            0     1       1      1         1     1      0  \n",
       "      the soft rug.                                                                                                \n",
       "  1   The dog napped               0     1        1    1            1     1       0      0         0     1      1  \n",
       "      peacefully on the warm                                                                                       \n",
       "      rug.                                                                                                         \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                                                                                   \n",
       " \u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSentence                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcat\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mdog\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mnapped\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mon\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mpeacefully\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrug\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mslept\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1msoft\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1msoundly\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mthe\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mwarm\u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  0   The cat slept soundly on     1     0        0    1            0     1       1      1         1     1      0  \n",
       "      the soft rug.                                                                                                \n",
       "  1   The dog napped               0     1        1    1            1     1       0      0         0     1      1  \n",
       "      peacefully on the warm                                                                                       \n",
       "      rug.                                                                                                         \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "\n",
    "console = Console()\n",
    "md = Markdown(df.to_markdown())\n",
    "console.print(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12016ce6-12cf-4e05-88c2-c2725091643e",
   "metadata": {},
   "source": [
    "# Dense embeddings from BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abba4613-1aae-47e3-a167-aaca3901bae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of dimensions in the sentence 1 embeddings = (10, 768)\n",
      "Sample embeddings[:5] = tensor([[-0.0146,  0.0706, -0.3223,  ..., -0.6195,  0.4784,  0.3209],\n",
      "        [-0.3229,  0.1109, -0.4878,  ..., -0.4270,  0.3301, -0.2171],\n",
      "        [ 0.0209,  0.3718, -0.1737,  ..., -0.4981,  0.2606,  0.5935],\n",
      "        [ 0.5665, -0.4937, -0.2265,  ..., -0.8287,  0.1734,  0.0389],\n",
      "        [ 0.1579, -0.2385,  0.2189,  ..., -0.0540,  0.2653,  0.0139]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# function to get BERT embeddings\n",
    "def get_bert_embeddings(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    embedding = last_hidden_states[0, :]  # +1 to account for [CLS] token\n",
    "    return embedding\n",
    "\n",
    "bert_embeddings = [get_bert_embeddings(d) for d in corpus]\n",
    "\n",
    "print(f\"# of dimensions in the sentence 1 embeddings = {tuple(bert_embeddings[0].shape)}\")\n",
    "print(f\"Sample embeddings[:5] = {bert_embeddings[1][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dadc53fa-c638-400a-bc79-59badf2baed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.2126, -0.2405, -0.5741,  ..., -0.4036,  0.7588,  0.4445],\n",
       "         [-0.4847, -0.5858, -0.2595,  ..., -0.7802,  0.9080, -0.0304],\n",
       "         [-0.2277, -0.1399,  0.0161,  ..., -1.0611,  0.3858,  0.6314],\n",
       "         ...,\n",
       "         [ 0.5969,  0.0696,  0.0393,  ..., -0.4466,  0.1420, -0.1435],\n",
       "         [-0.0929, -0.5271, -0.2424,  ...,  0.1697,  0.6789, -0.6303],\n",
       "         [ 0.5555, -0.0605, -0.3327,  ...,  0.0226, -0.3393, -0.3695]],\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([[-0.0146,  0.0706, -0.3223,  ..., -0.6195,  0.4784,  0.3209],\n",
       "         [-0.3229,  0.1109, -0.4878,  ..., -0.4270,  0.3301, -0.2171],\n",
       "         [ 0.0209,  0.3718, -0.1737,  ..., -0.4981,  0.2606,  0.5935],\n",
       "         ...,\n",
       "         [ 0.8921,  0.2020,  0.2865,  ..., -0.2967,  0.0288, -0.6615],\n",
       "         [ 0.1118, -0.6143, -0.1392,  ...,  0.3322,  0.5662, -0.6797],\n",
       "         [ 0.4856,  0.1500, -0.1191,  ...,  0.0294, -0.1803, -0.3612]],\n",
       "        grad_fn=<SliceBackward0>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings = [get_bert_embeddings(d) for d in corpus]\n",
    "bert_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "381847e2-cfc1-49ed-b985-91f744999ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings[1].shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "genai-gcp",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "genai-gcp (Local)",
   "language": "python",
   "name": "genai-gcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
